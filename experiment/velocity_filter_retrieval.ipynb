{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ubx_parser\n",
    "from matplotlib import pyplot as plt\n",
    "import importer\n",
    "import math\n",
    "from pyproj import Proj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from geopy.distance import great_circle\n",
    "import utils\n",
    "from scipy.signal import butter,filtfilt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(importer)\n",
    "importlib.reload(ubx_parser)\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "filename = 'ubx_records/ground_truth_1.ubx'\n",
    "ubx_1 = ubx_parser.read_ubx(filename)\n",
    "\n",
    "\n",
    "filename = 'ubx_records/ground_truth_2.ubx'\n",
    "ubx_2 = ubx_parser.read_ubx(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(importer)\n",
    "\n",
    "\n",
    "path = 'simra_records/'\n",
    "\n",
    "dfs = importer.import_files(path)\n",
    "\n",
    "mi9_1 = importer.preprocess_basics(dfs[2], True)\n",
    "a2_1 = importer.preprocess_basics(dfs[0], True)\n",
    "\n",
    "mi9_2 = importer.preprocess_basics(dfs[1], True)\n",
    "a2_2 = importer.preprocess_basics(dfs[3], True)\n",
    "\n",
    "experiments_ = [(ubx_1, [mi9_1, a2_1]), (ubx_2, [mi9_2, a2_2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for exp in experiments_:\n",
    "\n",
    "    ref_date_min = max(exp[1][0].date.min(), exp[1][1].date.min())\n",
    "\n",
    "    exp[1][0] = exp[1][0][exp[1][0].date >= ref_date_min]\n",
    "    exp[1][1] = exp[1][1][exp[1][1].date >= ref_date_min]\n",
    "\n",
    "    ref_date_max = min(exp[1][0].date.max(), exp[1][1].date.max())\n",
    "    exp[1][0] = exp[1][0][exp[1][0].date <= ref_date_max]\n",
    "    exp[1][1] = exp[1][1][exp[1][1].date <= ref_date_max]\n",
    "\n",
    "\n",
    "    comp = pd.merge_asof(exp[1][0].rename(columns={'date':'date_mi9'}), exp[1][1].rename(columns={'date':'date_a2'}), left_on='date_mi9', right_on='date_a2', suffixes=('_mi9', '_a2'), direction='nearest')\n",
    "\n",
    "\n",
    "    comp = comp[(comp['section_mi9'] >= 0) & (comp['section_a2'] >= 0)]\n",
    "\n",
    "\n",
    "    comp['date_diff'] = abs(comp['date_mi9'] - comp['date_a2'])\n",
    "\n",
    "    comp_ubx = pd.merge_asof(comp, exp[0][['coord_index', 'date', 'velo', 'x', 'y']].rename(columns={'date':'date_ubx', 'x': 'x_ubx', 'y': 'y_ubx'}), left_on='date_mi9', right_on='date_ubx', suffixes=('', '_ubx'), direction='nearest')\n",
    "\n",
    "    comp_ubx['velo_avg'] = comp_ubx.apply(lambda x: (x['velo_mi9'] + x['velo_a2'])/2, axis=1)\n",
    "\n",
    "    comp_ubx['rmse'] = mse(comp_ubx.velo, comp_ubx.velo_avg, squared=False)\n",
    "\n",
    "    \n",
    "    experiments.append((exp[0], [exp[1][0], exp[1][1]], comp_ubx))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "def find_best_MA_params(experiments, force_to_zero):\n",
    "\n",
    "    res = []\n",
    "    for exp in experiments: \n",
    "        comp = exp[2].copy()\n",
    "        \n",
    "        for w in np.linspace(1,40,40, dtype = int):\n",
    "            if not force_to_zero:\n",
    "                comp['velo_ma_mi9'] = comp.velo_mi9.rolling(w, center=True, min_periods=1).mean()\n",
    "                comp['velo_ma_a2'] = comp.velo_a2.rolling(w, center=True, min_periods=1).mean()\n",
    "            \n",
    "            else:\n",
    "                comp['velo_ma_mi9'] = np.where(comp.velo_mi9 < threshold, 0, comp.velo_mi9.rolling(w, center=True, min_periods=1).mean())\n",
    "                comp['velo_ma_a2'] = np.where(comp.velo_a2 < threshold, 0, comp.velo_a2.rolling(w, center=True, min_periods=1).mean())\n",
    "            \n",
    "            comp_ma = comp[~comp['velo_ma_mi9'].isnull() & ~comp['velo_ma_a2'].isnull()]            \n",
    "            comp_ma['velo_ma_avg'] = comp_ma.apply(lambda x: (x['velo_ma_mi9'] + x['velo_ma_a2'])/2, axis=1)\n",
    "            \n",
    "            comp_ma['rmse_MA'] = mse(comp_ma.velo, comp_ma.velo_ma_avg, squared=False)\n",
    "            res.append(np.array([w, comp_ma['rmse_MA'].mean()]))\n",
    "\n",
    "    res_raw = np.array(res)\n",
    "    tmp = pd.DataFrame(res_raw, columns=['w' ,'val'])\n",
    "\n",
    "    arr = np.array(tmp.groupby('w')['val'].mean().index.to_numpy())\n",
    "    res = np.vstack([arr, tmp.groupby('w')['val'].mean().to_numpy()]).T\n",
    "    return res[np.argmin(res[:,1])][0], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_params, ma_params_info = find_best_MA_params(experiments, False)\n",
    "ma_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_params0, ma_params_info0 = find_best_MA_params(experiments, True)\n",
    "ma_params0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_type = 'gaussian'\n",
    "threshold = 0.5\n",
    "\n",
    "def find_best_kernel_params(experiments, force_to_zero):\n",
    "\n",
    "    res = []\n",
    "    for exp in experiments:\n",
    "        comp = exp[2].copy()\n",
    "        for std in np.linspace(1, 4, 25):\n",
    "            for w in np.linspace(1, 80, 80).astype('int'):\n",
    "                if w % 2 != 0:  #  equal window sizes produce insufficient results\n",
    "                    continue\n",
    "                if not force_to_zero:\n",
    "                    comp['velo_k_mi9'] = comp.velo_mi9.rolling(window=w, win_type=win_type, center=True, min_periods = 1).mean(std=std)\n",
    "                    comp['velo_k_a2'] = comp.velo_a2.rolling(window=w, win_type=win_type, center=True, min_periods = 1).mean(std=std)\n",
    "                else:\n",
    "                    comp['velo_k_mi9'] = np.where(comp.velo_mi9 < threshold, 0, comp.velo_mi9.rolling(window=w, win_type=win_type, center=True, min_periods = 1).mean(std=std))\n",
    "                    comp['velo_k_a2'] = np.where(comp.velo_a2 < threshold, 0, comp.velo_a2.rolling(window=w, win_type=win_type, center=True, min_periods = 1).mean(std=std))\n",
    "\n",
    "                comp_k = comp[~comp['velo_k_mi9'].isnull() & ~comp['velo_k_a2'].isnull()]            \n",
    "                comp_k['velo_k_avg'] = comp_k.apply(lambda x: (x['velo_k_mi9'] + x['velo_k_a2'])/2, axis=1)\n",
    "\n",
    "                res.append(np.array([w, std, mse(comp_k.velo, comp_k.velo_k_avg, squared=False)]))\n",
    "                \n",
    "    res_raw = np.array(res)                                    \n",
    "    tmp = pd.DataFrame(res_raw, columns=['w', 'std', 'val'])\n",
    "\n",
    "    arr = np.array(tmp.groupby(['w', 'std'])['val'].mean().index.to_numpy())\n",
    "    res = np.vstack([arr, tmp.groupby(['w', 'std'])['val'].mean().to_numpy()]).T\n",
    "    return res[np.argmin(res[:,1])][0], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_params, k_params_info = find_best_kernel_params(experiments, False)\n",
    "kernel_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_params0, k_params_info0 = find_best_kernel_params(experiments, True)\n",
    "kernel_params0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass(data, order, fv):\n",
    "    b, a = butter(order, fv, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def find_best_low_pass_params(experiments, force_to_zero):\n",
    "\n",
    "    res=[]\n",
    "    for exp in experiments:\n",
    "        comp = exp[2].copy()\n",
    "        for order in np.linspace(1,10,10):\n",
    "            for fv in np.linspace(0.01,0.5,50):\n",
    "                if not force_to_zero:\n",
    "                    comp['velo_lp_mi9'] = low_pass(comp.velo_mi9, order, fv)\n",
    "                    comp['velo_lp_a2'] = low_pass(comp.velo_a2, order, fv)\n",
    "                else:\n",
    "                    comp['velo_lp_mi9'] = np.where(comp.velo_mi9 < threshold, 0, low_pass(comp.velo_mi9, order, fv))\n",
    "                    comp['velo_lp_a2'] = np.where(comp.velo_a2 < threshold, 0, low_pass(comp.velo_a2, order, fv))\n",
    "                \n",
    "                comp_lp = comp[~comp['velo_lp_mi9'].isnull() & ~comp['velo_lp_a2'].isnull()]            \n",
    "                comp_lp['velo_lp_avg'] = comp_lp.apply(lambda x: (x['velo_lp_mi9'] + x['velo_lp_a2'])/2, axis=1)\n",
    "                rmse = mse(comp_lp.velo, comp_lp.velo_lp_avg, squared=False)\n",
    "                res.append(np.array([order, fv, rmse]))\n",
    "                \n",
    "    res_raw = np.array(res)                                    \n",
    "    tmp = pd.DataFrame(res_raw, columns=['order', 'fv', 'val'])\n",
    "\n",
    "    arr = np.array(tmp.groupby(['order', 'fv'])['val'].mean().index.to_numpy())\n",
    "    res = np.vstack([arr, tmp.groupby(['order', 'fv'])['val'].mean().to_numpy()]).T\n",
    "    return res[np.argmin(res[:,1])][0], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_params, lp_params_info = find_best_low_pass_params(experiments, False)\n",
    "lp_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_params0, lp_params_info0 = find_best_low_pass_params(experiments, True)\n",
    "lp_params0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_errors = []\n",
    "ma_errors = []\n",
    "ma0_errors = []\n",
    "k_errors = []\n",
    "k0_errors = []\n",
    "lp_errors = []\n",
    "lp0_errors = []\n",
    "\n",
    "for exp in experiments: \n",
    "    raw_errors.append(mse(exp[2].velo, exp[2].velo_avg, squared=False))\n",
    "    \n",
    "    ma_w = int(ma_params)\n",
    "    exp[2]['velo_ma_a2'] = exp[2].velo_a2.rolling(ma_w, center=True, min_periods = 1).mean()\n",
    "    exp[2]['velo_ma_mi9'] = exp[2].velo_mi9.rolling(ma_w, center=True, min_periods = 1).mean()\n",
    "    exp[2]['velo_ma_avg'] = exp[2].apply(lambda x: (x['velo_ma_mi9'] + x['velo_ma_a2'])/2, axis=1)        \n",
    "    ma_errors.append(mse(exp[2].velo, exp[2].velo_ma_avg, squared=False))\n",
    "    \n",
    "    ma_w0 = int(ma_params0)\n",
    "    exp[2]['velo_ma0_a2'] = np.where(exp[2].velo_a2.rolling(ma_w0, center=True, min_periods = 1).mean() < threshold, 0, exp[2].velo_a2.rolling(ma_w0, center=True, min_periods = 1).mean())\n",
    "    exp[2]['velo_ma0_mi9'] = np.where(exp[2].velo_mi9.rolling(ma_w0, center=True, min_periods = 1).mean() < threshold, 0, exp[2].velo_mi9.rolling(ma_w0, center=True, min_periods = 1).mean())\n",
    "    exp[2]['velo_ma0_avg'] = exp[2].apply(lambda x: (x['velo_ma0_mi9'] + x['velo_ma0_a2'])/2, axis=1)        \n",
    "    ma0_errors.append(mse(exp[2].velo, exp[2].velo_ma0_avg, squared=False))    \n",
    "    \n",
    "    \n",
    "    kernel_w = int(kernel_params[0])\n",
    "    kernel_std = kernel_params[1]\n",
    "    win_type = 'gaussian'\n",
    "    exp[2]['velo_k_a2'] =  exp[2].velo_a2.rolling(window=kernel_w, win_type=win_type, center=True, min_periods = 1).mean(std=kernel_std)\n",
    "    exp[2]['velo_k_mi9'] =  exp[2].velo_mi9.rolling(window=kernel_w, win_type=win_type, center=True, min_periods = 1).mean(std=kernel_std)\n",
    "    exp[2]['velo_k_avg'] = exp[2].apply(lambda x: (x['velo_k_mi9'] + x['velo_k_a2'])/2, axis=1)        \n",
    "    k_errors.append(mse(exp[2].velo, exp[2].velo_k_avg, squared=False))    \n",
    "    \n",
    "    kernel_w0 = int(kernel_params0[0])\n",
    "    kernel_std0 = kernel_params0[1]\n",
    "    win_type = 'gaussian'\n",
    "    exp[2]['velo_k0_a2'] =  np.where(exp[2].velo_a2 < threshold, 0, exp[2].velo_a2.rolling(window=kernel_w0, win_type=win_type, center=True, min_periods = 1).mean(std=kernel_std0))\n",
    "    exp[2]['velo_k0_mi9'] =  np.where(exp[2].velo_mi9 < threshold, 0, exp[2].velo_mi9.rolling(window=kernel_w0, win_type=win_type, center=True, min_periods = 1).mean(std=kernel_std0))\n",
    "    exp[2]['velo_k0_avg'] = exp[2].apply(lambda x: (x['velo_k0_mi9'] + x['velo_k0_a2'])/2, axis=1)        \n",
    "    k0_errors.append(mse(exp[2].velo, exp[2].velo_k0_avg, squared=False))\n",
    "    \n",
    "    \n",
    "    lp_order = int(lp_params[0])\n",
    "    lp_filter_value = lp_params[1]\n",
    "    exp[2]['velo_lp_a2'] = low_pass(exp[2].velo_a2, lp_order, lp_filter_value)\n",
    "    exp[2]['velo_lp_mi9'] = low_pass(exp[2].velo_mi9, lp_order, lp_filter_value)\n",
    "    exp[2]['velo_lp_avg'] = exp[2].apply(lambda x: (x['velo_lp_mi9'] + x['velo_lp_a2'])/2, axis=1)        \n",
    "    lp_errors.append(mse(exp[2].velo, exp[2].velo_lp_avg, squared=False))\n",
    "    \n",
    "    lp_order0 = int(lp_params0[0])\n",
    "    lp_filter_value0 = lp_params0[1]\n",
    "    exp[2]['velo_lp0_a2'] = np.where(exp[2].velo_a2 < threshold, 0, low_pass(exp[2].velo_a2, lp_order0, lp_filter_value0))\n",
    "    exp[2]['velo_lp0_mi9'] = np.where(exp[2].velo_mi9 < threshold, 0, low_pass(exp[2].velo_mi9, lp_order0, lp_filter_value0))\n",
    "    exp[2]['velo_lp0_avg'] = exp[2].apply(lambda x: (x['velo_lp0_mi9'] + x['velo_lp0_a2'])/2, axis=1)        \n",
    "    lp0_errors.append(mse(exp[2].velo, exp[2].velo_lp0_avg, squared=False)) \n",
    "\n",
    "    f = 150\n",
    "    t = 200\n",
    "    \n",
    "    plt.plot(exp[2].date_mi9[f:t], exp[2].velo[f:t], label='ubx')\n",
    "    plt.plot(exp[2].date_mi9[f:t], exp[2].velo_avg[f:t], label='raw')\n",
    "    plt.plot(exp[2].date_mi9[f:t], exp[2].velo_ma_avg[f:t], label='avg_ma')\n",
    "    plt.plot(exp[2].date_mi9[f:t], exp[2].velo_k_avg[f:t], label='avg_kernel')\n",
    "    plt.plot(exp[2].date_mi9[f:t], exp[2].velo_lp_avg[f:t], label='avg_lp')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "mean_raw_error = np.mean(raw_errors)\n",
    "mean_ma_error = np.mean(ma_errors)\n",
    "mean_ma0_error = np.mean(ma0_errors)\n",
    "mean_k_error = np.mean(k_errors)\n",
    "mean_k0_error = np.mean(k0_errors)\n",
    "mean_lp_error = np.mean(lp_errors)\n",
    "mean_lp0_error = np.mean(lp0_errors)\n",
    "\n",
    "print('Avg velo RMSE: \\t\\t\\t', mean_raw_error)\n",
    "print('Avg velo RMSE MA: \\t\\t', mean_ma_error, '\\t (', (mean_ma_error/mean_raw_error) - 1,')')\n",
    "print('Avg velo RMSE MA0: \\t\\t', mean_ma0_error, '\\t (', (mean_ma0_error/mean_raw_error) - 1, ')')\n",
    "print('Avg velo RMSE Kernel: \\t\\t', mean_k_error, '\\t (', (mean_k_error/mean_raw_error) - 1, ')')\n",
    "print('Avg velo RMSE Kernel 0: \\t', mean_k0_error, '\\t (', (mean_k0_error/mean_raw_error) - 1, ')')\n",
    "print('Avg velo RMSE LP: \\t\\t', mean_lp_error, '\\t (', (mean_lp_error/mean_raw_error) - 1, ')')\n",
    "print('Avg velo RMSE LP0: \\t\\t', mean_lp0_error, '\\t (', (mean_lp0_error/mean_raw_error) - 1, ')')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = []\n",
    "for info in k_params_info:\n",
    "    infos.append([info[0][0], info[0][1], info[1]])\n",
    "    \n",
    "df = pd.DataFrame(infos, columns=['w', 'std', 'val'])\n",
    "df = df[df['std'] == kernel_params[1]]\n",
    "\n",
    "\n",
    "plt.plot(df.w, (df.val/mean_raw_error) - 1, color='red')\n",
    "plt.ylabel('relative error',color='red',fontsize=14)\n",
    "plt.xlabel('window size (std = %.2f)'%kernel_params[1],fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(infos, columns=['w', 'std', 'val'])\n",
    "df = df[df['w'] == kernel_params[0]]\n",
    "plt.plot(df['std'], (df.val/mean_raw_error) - 1, color='red')\n",
    "plt.ylabel('relative error',color='red',fontsize=14)\n",
    "plt.xlabel('kernel std (window size = %i)'%kernel_params[0],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ma_params_info, columns=['w', 'val'])\n",
    "\n",
    "plt.plot(df.w, (df.val/mean_raw_error) - 1, color='red')\n",
    "\n",
    "plt.ylabel('error',color='red',fontsize=14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = []\n",
    "for info in lp_params_info:\n",
    "    infos.append([info[0][0], info[0][1], info[1]])\n",
    "\n",
    "tmp = pd.DataFrame(infos, columns=['order', 'fv', 'val'])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.title('fv fixed at %.2f'%lp_params[1])\n",
    "plt.plot(tmp[tmp['fv'] == lp_params[1]]['order'], tmp[tmp['fv'] == lp_params[1]]['val']/mean_raw_error - 1)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('order fixed at %i'%lp_params[0])\n",
    "plt.plot(tmp[tmp['order'] == lp_params[0]]['fv'], tmp[tmp['order'] == lp_params[0]]['val'] /mean_raw_error - 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
