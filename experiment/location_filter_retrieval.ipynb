{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ubx_parser\n",
    "from matplotlib import pyplot as plt\n",
    "import importer\n",
    "import math\n",
    "from pyproj import Proj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from geopy.distance import great_circle\n",
    "import utils\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(importer)\n",
    "importlib.reload(ubx_parser)\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "filename = 'ubx_records/ground_truth_1.ubx'\n",
    "ubx_1 = ubx_parser.read_ubx(filename)\n",
    "\n",
    "\n",
    "filename = 'ubx_records/ground_truth_2.ubx'\n",
    "ubx_2 = ubx_parser.read_ubx(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importer\n",
    "import importlib\n",
    "importlib.reload(importer)\n",
    "\n",
    "\n",
    "path = 'simra_records/'\n",
    "\n",
    "dfs = importer.import_files(path)\n",
    "\n",
    "#ride 1: mi9 = 14, a2 = 7 (ride Nr 6) sl_6\n",
    "#ride 3: mi9 = 11, a2 = 6) sl_7\n",
    "\n",
    "mi9_1 = importer.preprocess_basics(dfs[2], True)\n",
    "a2_1 = importer.preprocess_basics(dfs[0], True)\n",
    "\n",
    "mi9_2 = importer.preprocess_basics(dfs[1], True)\n",
    "a2_2 = importer.preprocess_basics(dfs[3], True)\n",
    "\n",
    "experiments = [(ubx_1, [mi9_1, a2_1]), (ubx_2, [mi9_2, a2_2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Die Frage ist hier, ob der Avg der Coords zum selben Zeitpunkt genommen werden sollten. \n",
    "## In dieser Zelle werden die Smartphone Measurements den jeweils nächstesn UBX Werten zugeordnet. An allen UBX Werten werden\n",
    "## dann die Avgs gebildet. Da UBX Measurement Frequenz höher ist, gibt es sehr viele UBX Measurements mit nur einem \n",
    "## Smartphone Measurement Wert. Hier ist Avg dann ünnötig. Ist der Ansatz sinnvoll? -> JA! Siehe Thesis Algorithm 1 und Erläuternungen\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calc_means(data_sources, ubx_coords):\n",
    "    mapped_on_ubx_dicts = []\n",
    "    for ds in data_sources:\n",
    "        mapped_on_ubx = calc_closest_ubx_points(ds, ubx_coords)\n",
    "        mapped_on_ubx_dict = { i : mapped_on_ubx[i] for i in range(0, len(mapped_on_ubx) ) }\n",
    "        \n",
    "        a_s = defaultdict(list)\n",
    "\n",
    "        for k, v in mapped_on_ubx_dict.items():\n",
    "            a_s[v].append(k)\n",
    "\n",
    "        a_s = dict(a_s)\n",
    "        mapped_on_ubx_dicts.append(a_s)\n",
    "    \n",
    "    means = []\n",
    "    for i in range(len(ubx_coords)):\n",
    "        coords_p = []\n",
    "        for data_source_index, coord_dict in enumerate(mapped_on_ubx_dicts):\n",
    "            if i in coord_dict:\n",
    "                for j in coord_dict[i]:\n",
    "                    coords_p.append(data_sources[data_source_index][j])\n",
    "        ## HUGE HEURISTIC!! Mean is only computed, if 2 or more cellphone coordinates are assigned to UBX coord. If <2 there is no actual mean. It would be just the distance to one ride.\n",
    "        if len(coords_p) > 1:\n",
    "            means.append(np.mean(coords_p, axis=0))\n",
    "    return means\n",
    "\n",
    "\n",
    "def calc_mean_deviation_from_ubx(data_sources, ubx):\n",
    "    ubx_coords = ubx[['x', 'y']].values\n",
    "    means = calc_means(data_sources, ubx_coords)\n",
    "    return np.mean(calc_dists(means, ubx_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dists(coords1, coords2):\n",
    "    metric = \"euclidean\"\n",
    "    dist = cdist(coords1, coords2, metric=metric)\n",
    "    return dist.min(axis=1)\n",
    "             \n",
    "\n",
    "def calc_closest_ubx_points(coords, ubx_coords):\n",
    "    metric = \"euclidean\"\n",
    "    dist = cdist(coords, ubx_coords, metric=metric)\n",
    "    return np.argmin(dist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import predict, update\n",
    "\n",
    "def create_F(dt):\n",
    "    return np.array([[1, 1*dt, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 1, 1*dt],\n",
    "                     [0, 0, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.common import Q_continuous_white_noise\n",
    "\n",
    "def run_kf(data, r_factor):\n",
    "\n",
    "    df_kf = data.copy()\n",
    "\n",
    "    dts = (df_kf['date'] - df_kf.shift(1)['date']).dt.total_seconds().to_numpy()\n",
    "    dt_mean = np.mean(np.nan_to_num(dts))\n",
    "    measurements = df_kf[['x', 'y']].values\n",
    "\n",
    "    x = np.array([measurements[0][0], 0, measurements[0][1], 0])\n",
    "\n",
    "    F = create_F(dts[0])\n",
    "\n",
    "    accs = df_kf['acc'].to_numpy()\n",
    "\n",
    "    H = np.array([[1, 0, 0, 0],\n",
    "                  [0, 0, 1, 0]])\n",
    "\n",
    "    P = np.array([[accs[0]**2., 0., 0., 0.],\n",
    "                [0., 1., 0., 0.], \n",
    "                [0., 0., accs[0]**2., 0.],\n",
    "                [0., 0., 0., 1.]])\n",
    "\n",
    "    R = np.eye(2) * accs[0]**2 * r_factor\n",
    "\n",
    "    Q = Q_continuous_white_noise(dim=4, dt=dts[0])\n",
    "    # Kinematic systems are continuous - their inputs and outputs can vary at any arbitrary point in time. (https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/07-Kalman-Filter-Math.ipynb)\n",
    "\n",
    "    res = []\n",
    "    f_ = 0\n",
    "    t_ = len(df_kf)\n",
    "\n",
    "\n",
    "    for i in range(f_, t_):\n",
    "        z = measurements[i]\n",
    "        if i == 0:\n",
    "            dt = dts[1]\n",
    "        else:\n",
    "            dt = dts[i]\n",
    "        F = create_F(dt)\n",
    "        R = np.eye(2) * accs[i]**2 *r_factor\n",
    "        Q = Q_continuous_white_noise(dim=4, dt=dt)\n",
    "        x, P = predict(x, P, F, Q)    \n",
    "        x, P = update(x, P, z, R, H)\n",
    "        res.append(x)\n",
    "    res = np.array(res)\n",
    "\n",
    "    data['x_kf'] = res[:,0]\n",
    "    data['y_kf'] = res[:,2]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_KF_params(experiments):\n",
    "    res = []\n",
    "    for exp in experiments:\n",
    "        data_sources_dfs = exp[1]\n",
    "        for r_factor in np.linspace(1,10,19):\n",
    "            kf_filtered = []\n",
    "            for ds in data_sources_dfs:\n",
    "                ds = run_kf(ds, r_factor)\n",
    "                kf_filtered.append(ds[['x_kf', 'y_kf']].to_numpy())\n",
    "\n",
    "            res.append(np.array([r_factor, calc_mean_deviation_from_ubx(kf_filtered, exp[0])]))\n",
    "\n",
    "    res = np.array(res)\n",
    "    tmp = pd.DataFrame(res, columns=['fac', 'val'])\n",
    "    arr = np.array(tmp.groupby('fac')['val'].mean().index.to_numpy())\n",
    "    res = np.vstack([arr, tmp.groupby('fac')['val'].mean().to_numpy()]).T\n",
    "    return res[np.argmin(res[:,1])][0], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_params, kf_params_info = find_best_KF_params(experiments)\n",
    "kf_params_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_MA_params(experiments):\n",
    "    res = []\n",
    "    for exp in experiments:\n",
    "        \n",
    "        data_sources = []\n",
    "        for df in exp[1]:\n",
    "            data_sources.append(df[['x', 'y']].to_numpy())\n",
    "        \n",
    "        for w in np.linspace(1,40,40, dtype = int):  \n",
    "            ma_filtered = []\n",
    "            for ds in data_sources:\n",
    "                df = pd.DataFrame(ds, columns=['x', 'y'])\n",
    "                df['x_ma'] = df.x.rolling(w, center=True, min_periods = 1).mean()\n",
    "                df['y_ma'] = df.y.rolling(w, center=True, min_periods = 1).mean()\n",
    "                ma_filtered.append(df[['x_ma', 'y_ma']].to_numpy())\n",
    "\n",
    "            res.append(np.array([w, calc_mean_deviation_from_ubx(ma_filtered, exp[0])]))\n",
    "\n",
    "    res_raw = np.array(res)\n",
    "    tmp = pd.DataFrame(res_raw, columns=['w','val'])\n",
    "\n",
    "    arr = np.array(tmp.groupby('w')['val'].mean().index.to_numpy())\n",
    "    res = np.vstack([arr, tmp.groupby('w')['val'].mean().to_numpy()]).T\n",
    "    return res[np.argmin(res[:,1])][0], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_params, ma_params_info = find_best_MA_params(experiments)\n",
    "ma_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_type = 'gaussian'\n",
    "\n",
    "def find_best_kernel_params(experiments):\n",
    "\n",
    "    res = []\n",
    "    for exp in experiments: \n",
    "        data_sources = []\n",
    "        for df in exp[1]:\n",
    "            data_sources.append(df[['x', 'y']].to_numpy())\n",
    "            \n",
    "        for std in np.linspace(1, 4, 25):\n",
    "            for w in np.linspace(1, 40, 40).astype('int'):\n",
    "                if w % 2 != 0:\n",
    "                    continue\n",
    "                k_filtered = []\n",
    "                for ds in data_sources:\n",
    "                    df = pd.DataFrame(ds, columns=['x', 'y'])\n",
    "                    df['x_k'] = df.x.rolling(window=w, win_type=win_type, center=True, min_periods = 1).mean(std=std)\n",
    "                    df['y_k'] = df.y.rolling(window=w, win_type=win_type, center=True, min_periods = 1).mean(std=std)\n",
    "                    k_filtered.append(df[['x_k', 'y_k']].to_numpy())\n",
    "\n",
    "                res.append(np.array([w, std, calc_mean_deviation_from_ubx(k_filtered, exp[0])]))\n",
    "\n",
    "    res_raw = np.array(res)                                    \n",
    "    tmp = pd.DataFrame(res_raw, columns=['w', 'std', 'val'])\n",
    "\n",
    "    arr = np.array(tmp.groupby(['w', 'std'])['val'].mean().index.to_numpy())\n",
    "    res = np.vstack([arr, tmp.groupby(['w', 'std'])['val'].mean().to_numpy()]).T\n",
    "    return res[np.argmin(res[:,1])][0], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_params, k_params_info = find_best_kernel_params(experiments)\n",
    "kernel_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datas = []\n",
    "kf_datas = []\n",
    "ma_datas = []\n",
    "k_datas = []\n",
    "\n",
    "for exp in experiments:\n",
    "    \n",
    "    raw_data = []\n",
    "    kf_data = []\n",
    "    ma_data = []\n",
    "    k_data = []\n",
    "\n",
    "    ubx = exp[0]\n",
    "    ubx_coords = ubx[['x', 'y']].to_numpy()\n",
    "    \n",
    "    for ds in exp[1]:\n",
    "\n",
    "        coords = ds[['x', 'y']].to_numpy()\n",
    "        raw_data.append(coords)\n",
    "        \n",
    "        comp = pd.DataFrame()\n",
    "        comp['error'] = calc_dists(coords, ubx_coords)\n",
    "\n",
    "        kf_tmp = run_kf(ds, kf_params)\n",
    "        kf_coords = kf_tmp[['x_kf', 'y_kf']].values\n",
    "        comp['error_KF'] = calc_dists(kf_coords, ubx_coords)\n",
    "        kf_data.append(kf_coords)\n",
    "\n",
    "        ma_w = int(ma_params)\n",
    "        ma_tmp = pd.DataFrame(coords, columns=['x', 'y'])\n",
    "        ma_tmp['x_ma'] = ma_tmp.x.rolling(ma_w, center=True, min_periods=1).mean()\n",
    "        ma_tmp['y_ma'] = ma_tmp.y.rolling(ma_w, center=True, min_periods=1).mean()\n",
    "        ma_coords = ma_tmp[['x_ma', 'y_ma']].values\n",
    "        comp['error_MA'] = calc_dists(ma_coords, ubx_coords)\n",
    "        ma_data.append(ma_coords)\n",
    "\n",
    "\n",
    "        kernel_w = int(kernel_params[0])\n",
    "        kernel_std = kernel_params[1]\n",
    "        win_type = 'gaussian'\n",
    "        k_tmp = pd.DataFrame(coords, columns=['x', 'y'])\n",
    "        k_tmp['x_k'] = k_tmp.x.rolling(window=kernel_w, win_type=win_type, center=True, min_periods=1).mean(std=kernel_std)\n",
    "        k_tmp['y_k'] = k_tmp.y.rolling(window=kernel_w, win_type=win_type, center=True, min_periods=1).mean(std=kernel_std)\n",
    "        k_coords = k_tmp[['x_k', 'y_k']].values\n",
    "        comp['error_K'] = calc_dists(k_coords, ubx_coords)\n",
    "        k_data.append(k_coords)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "\n",
    "        f = 150\n",
    "        t = 180\n",
    "\n",
    "        plt.scatter(ubx[ubx.date.between(ds[f:t].iloc[0].date, ds[f:t].iloc[-1].date)].x, ubx[ubx.date.between(ds[f:t].iloc[0].date, ds[f:t].iloc[-1].date)].y, label='ubx')\n",
    "        plt.scatter(coords[:,0][f:t], coords[:,1][f:t], label='raw')\n",
    "        plt.scatter(ma_tmp.x_ma[f:t], ma_tmp.y_ma[f:t], label='cell_ma')\n",
    "        plt.scatter(k_tmp.x_k[f:t], k_tmp.y_k[f:t], label='cell_kernel')\n",
    "        plt.scatter(kf_tmp.x_kf[f:t], kf_tmp.y_kf[f:t], label='cell_KF')\n",
    "\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        #plt.plot(comp_p10.date, comp_p10.error)\n",
    "\n",
    "        raw_error = comp['error'].mean()\n",
    "        print('mean coord error: \\t\\t', raw_error)\n",
    "        print('mean coord error MA: \\t\\t', comp['error_MA'].mean(), '\\t (', (comp['error_MA'].mean()/raw_error) - 1, ')')\n",
    "        print('mean coord error Kernel: \\t', comp['error_K'].mean(), '\\t (', (comp['error_K'].mean()/raw_error) - 1, ')')\n",
    "        print('mean coord error KF: \\t\\t', comp['error_KF'].mean(), '\\t (', (comp['error_KF'].mean()/raw_error) - 1, ')')\n",
    "        #print('P10 mean coord error: \\t', comp_p10.error.mean())\n",
    "        \n",
    "    raw_datas.append(raw_data)\n",
    "    kf_datas.append(kf_data)\n",
    "    ma_datas.append(ma_data)\n",
    "    k_datas.append(k_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_errors = []\n",
    "ma_errors = []\n",
    "k_errors = []\n",
    "kf_errors = []\n",
    "\n",
    "for i, exp in enumerate(experiments):   \n",
    "    raw_errors.append(calc_mean_deviation_from_ubx([exp[1][0][['x', 'y']].to_numpy(), exp[1][1][['x', 'y']].to_numpy()], exp[0]))\n",
    "    kf_errors.append(calc_mean_deviation_from_ubx(kf_datas[i], exp[0]))\n",
    "    ma_errors.append(calc_mean_deviation_from_ubx(ma_datas[i], exp[0]))\n",
    "    k_errors.append(calc_mean_deviation_from_ubx(k_datas[i], exp[0]))\n",
    "\n",
    "print('Avg coords mean coord error: \\t\\t', np.mean(raw_errors))\n",
    "print('Avg coords mean coord error MA: \\t', np.mean(ma_errors), '\\t (', (np.mean(ma_errors)/np.mean(raw_errors)) - 1,')')\n",
    "print('Avg coords mean coord error Kernel: \\t', np.mean(k_errors), '\\t (', (np.mean(k_errors)/np.mean(raw_errors)) - 1, ')')\n",
    "print('Avg coords mean coord error KF: \\t', np.mean(kf_errors), '\\t (', (np.mean(kf_errors)/np.mean(raw_errors)) - 1, ')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_means = np.array(calc_means(raw_data, ubx_coords))\n",
    "kf_means = np.array(calc_means(kf_data, ubx_coords))\n",
    "ma_means = np.array(calc_means(ma_data, ubx_coords))\n",
    "k_means = np.array(calc_means(k_data, ubx_coords))\n",
    "\n",
    "\n",
    "def inverse_project(coords):\n",
    "    proj = Proj('epsg:5243')\n",
    "    return proj(coords[0], coords[1], inverse=True)\n",
    "\n",
    "proj_ubx = np.apply_along_axis(inverse_project, 1, ubx_coords)\n",
    "proj_raw_means = np.apply_along_axis(inverse_project, 1, raw_means)\n",
    "proj_kf_means = np.apply_along_axis(inverse_project, 1, kf_means)\n",
    "proj_ma_means = np.apply_along_axis(inverse_project, 1, ma_means)\n",
    "proj_k_means = np.apply_along_axis(inverse_project, 1, k_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = plt.figure(figsize=(15,15))\n",
    "plt.plot(proj_ubx[:,0], proj_ubx[:,1], linewidth=2, label='raw means')\n",
    "plt.scatter(proj_raw_means[:,0], proj_raw_means[:,1], label='raw means')\n",
    "plt.scatter(proj_kf_means[:,0], proj_kf_means[:,1], label='kf means')\n",
    "plt.scatter(proj_ma_means[:,0], proj_ma_means[:,1], label='ma means')\n",
    "plt.scatter(proj_k_means[:,0], proj_k_means[:,1], label='k means')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation of Kernel Params\n",
    "\n",
    "infos = []\n",
    "for info in k_params_info:\n",
    "    infos.append([info[0][0], info[0][1], info[1]])\n",
    "\n",
    "df = pd.DataFrame(infos, columns=['w', 'std', 'val'])\n",
    "df = df[df['std'] == kernel_params[1]]\n",
    "\n",
    "\n",
    "plt.plot(df.w, (df.val/np.mean(raw_errors)) - 1, color='red')\n",
    "plt.ylabel('relative error',color='red',fontsize=14)\n",
    "plt.xlabel('window size (std = %.2f)'%kernel_params[1],fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(infos, columns=['w', 'std', 'val'])\n",
    "df = df[df['w'] == kernel_params[0]]\n",
    "plt.plot(df['std'], (df.val/np.mean(raw_errors)) - 1, color='red')\n",
    "plt.ylabel('relative error',color='red',fontsize=14)\n",
    "plt.xlabel('kernel std (window size = %i)'%kernel_params[0],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation of MA Params\n",
    "\n",
    "df = pd.DataFrame(ma_params_info, columns=['w', 'val'])\n",
    "\n",
    "plt.plot(df.w, (df.val/np.mean(raw_errors)) - 1, color='red')\n",
    "\n",
    "plt.ylabel('error',color='red',fontsize=14)\n",
    "plt.xlabel('window size',fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of KF-Params\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(kf_params_info[:,0], (kf_params_info[:,1]/np.mean(raw_errors)) - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
